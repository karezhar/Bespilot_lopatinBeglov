import os
import cv2
import torch
import numpy as np
from ultralytics import YOLO
from tqdm import tqdm
import argparse
import shutil


def main():
    print("üöÄ === –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ù–ê –í–ê–õ–ò–î–ê–¶–ò–û–ù–ù–´–• –î–ê–ù–ù–´–• ===")
    print("=" * 60)

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    parser = argparse.ArgumentParser(description='–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏')
    parser.add_argument('--sequence', type=str, required=True,
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä uav0000086_00000_v)')
    parser.add_argument('--model', type=str, default='best.pt',
                        help='–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLO')
    parser.add_argument('--conf', type=float, default=0.3,
                        help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏')
    parser.add_argument('--fps', type=int, default=30,
                        help='–ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ')
    args = parser.parse_args()

    # –ë–∞–∑–æ–≤—ã–µ –ø—É—Ç–∏
    BASE_DIR = os.path.expanduser('~/Bespilot_lopatinBeglov')
    VAL_DIR = os.path.join(BASE_DIR, 'VisDrone2019-VID-val')
    RESULTS_DIR = os.path.join(BASE_DIR, 'validation_results')

    # –°–æ–∑–¥–∞–µ–º —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(RESULTS_DIR, exist_ok=True)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device.upper()}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("\nü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO...")
    model_path = os.path.join(BASE_DIR, 'results', 'yolo_training2', 'weights', args.model)

    if not os.path.exists(model_path):
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å
        model_path = os.path.join(BASE_DIR, 'results', 'yolo_training', args.model)
        if not os.path.exists(model_path):
            print(f"‚ùå –û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {args.model}")
            return

    model = YOLO(model_path)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {os.path.basename(model_path)}")

    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    seq_path = os.path.join(VAL_DIR, 'sequences', args.sequence)
    ann_path = os.path.join(VAL_DIR, 'annotations', f"{args.sequence}.txt")

    if not os.path.exists(seq_path):
        print(f"‚ùå –û—à–∏–±–∫–∞: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {seq_path}")
        return

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    images = sorted([f for f in os.listdir(seq_path) if f.endswith('.jpg')])
    if not images:
        print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {seq_path}")
        return

    print(f"\nüìπ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {args.sequence}")
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤: {len(images)}")
    print(f"  FPS: {args.fps}")
    print(f"  –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {args.conf}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ –ø–æ –ø–µ—Ä–≤–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    first_image = cv2.imread(os.path.join(seq_path, images[0]))
    height, width, _ = first_image.shape

    # –°–æ–∑–¥–∞–µ–º VideoWriter
    output_video = os.path.join(RESULTS_DIR, f"{args.sequence}_detection.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video, fourcc, args.fps, (width, height))

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
    print("\nüé¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π...")
    progress_bar = tqdm(images, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤", unit="–∫–∞–¥—Ä")

    for img_name in progress_bar:
        img_path = os.path.join(seq_path, img_name)
        frame = cv2.imread(img_path)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é
        results = model.predict(
            source=frame,
            conf=args.conf,
            device=device,
            verbose=False
        )

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
        boxes = results[0].boxes.xyxy.cpu().numpy()
        classes = results[0].boxes.cls.cpu().numpy()
        confidences = results[0].boxes.conf.cpu().numpy()

        # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –∑–µ–ª–µ–Ω–æ–π –æ–∫–∞–Ω—Ç–æ–≤–∫–æ–π
        for box, cls_id, conf in zip(boxes, classes, confidences):
            x1, y1, x2, y2 = map(int, box)

            # –†–∏—Å—É–µ–º –∑–µ–ª–µ–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # –ü–æ–¥–ø–∏—Å—å —Å –∫–ª–∞—Å—Å–æ–º –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            label = f"{model.names[int(cls_id)]} {conf:.2f}"
            cv2.putText(frame, label, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–¥—Ä –≤ –≤–∏–¥–µ–æ
        out.write(frame)

    out.release()
    progress_bar.close()

    # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∫–∞–¥—Ä–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    print("\nüé¨ –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∫–∞–¥—Ä–∞–º–∏...")
    original_video = os.path.join(RESULTS_DIR, f"{args.sequence}_original.mp4")
    orig_out = cv2.VideoWriter(original_video, fourcc, args.fps, (width, height))

    for img_name in tqdm(images, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤", unit="–∫–∞–¥—Ä"):
        img_path = os.path.join(seq_path, img_name)
        frame = cv2.imread(img_path)
        orig_out.write(frame)

    orig_out.release()

    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (side-by-side)
    print("\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ...")
    combined_video = os.path.join(RESULTS_DIR, f"{args.sequence}_comparison.mp4")

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –æ–±–∞ –≤–∏–¥–µ–æ
    cap_orig = cv2.VideoCapture(original_video)
    cap_det = cv2.VideoCapture(output_video)

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –≤–∏–¥–µ–æ
    combined_width = width * 2
    combined_out = cv2.VideoWriter(combined_video, fourcc, args.fps, (combined_width, height))

    frame_count = len(images)
    for _ in tqdm(range(frame_count), desc="–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ", unit="–∫–∞–¥—Ä"):
        ret_orig, frame_orig = cap_orig.read()
        ret_det, frame_det = cap_det.read()

        if not ret_orig or not ret_det:
            break

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–∞–¥—Ä—ã –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
        combined_frame = np.hstack((frame_orig, frame_det))

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
        cv2.putText(combined_frame, "Original", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(combined_frame, "Detection", (width + 10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        combined_out.write(combined_frame)

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ —Ä–µ—Å—É—Ä—Å—ã
    cap_orig.release()
    cap_det.release()
    combined_out.release()

    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã
    os.remove(original_video)
    os.remove(output_video)

    print("\n" + "=" * 60)
    print("üéâ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
    print("=" * 60)
    print(f"üíæ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {combined_video}")
    print(f"\nüì• –î–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É:")
    print(f"scp user001@server_ip:{combined_video} .")
    print(f"\nüñºÔ∏è –†–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ: {width * 2}x{height} (–æ—Ä–∏–≥–∏–Ω–∞–ª + –¥–µ—Ç–µ–∫—Ü–∏—è)")
    print(f"‚è±Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {frame_count / args.fps:.1f} —Å–µ–∫—É–Ω–¥")


if __name__ == "__main__":
    main()